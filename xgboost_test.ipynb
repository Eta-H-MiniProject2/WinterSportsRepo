{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('data_by_location/Kasurila_data.csv') # Error 8.88\n",
    "#df = pd.read_csv('data_by_location/Levi_data.csv') # Error 17.05\n",
    "#df = pd.read_csv('data_by_location/Luosto_data.csv') # Error 13.97\n",
    "#df = pd.read_csv('data_by_location/Messila_data.csv') # Error 6.61\n",
    "#df = pd.read_csv('data_by_location/Mustavaara_data.csv') # Error 9.38\n",
    "#df = pd.read_csv('data_by_location/Ounasvaara_data.csv') # Error 12.27\n",
    "#df = pd.read_csv('data_by_location/Purnu_data.csv') # Error 8.10\n",
    "#df = pd.read_csv('data_by_location/Ruka_data.csv') # Error 11.46\n",
    "#df = pd.read_csv('data_by_location/Ruunarinteet_data.csv') # Error 7.28\n",
    "#df = pd.read_csv('data_by_location/Salla_data.csv') # Error 13.26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_with_time_features(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Remove duplicates\n",
    "    df = df.drop_duplicates(subset=['date'], keep='last')\n",
    "    \n",
    "    # Replace values\n",
    "    df.replace(to_replace='-', value=np.nan, inplace=True)\n",
    "    df.snow_depth_cm = df.snow_depth_cm.replace(to_replace='-1', value='0')\n",
    "\n",
    "    # Delete rows where snow_depth is null\n",
    "    df = df.dropna(subset=['snow_depth_cm'])\n",
    "\n",
    "    # Convert to numeric\n",
    "    df['avg_temp_c'] = pd.to_numeric(df['avg_temp_c'], errors='coerce')\n",
    "    df['snow_depth_cm'] = pd.to_numeric(df['snow_depth_cm'], errors='coerce')\n",
    "    df['uv_index'] = pd.to_numeric(df['uv_index'], errors='coerce')\n",
    "    \n",
    "    # Create lag features\n",
    "    df['snow_depth_1d_ago'] = df['snow_depth_cm'].shift(1)\n",
    "    df['snow_depth_7d_ago'] = df['snow_depth_cm'].shift(7)\n",
    "    df['snow_depth_365d_ago'] = df['snow_depth_cm'].shift(365)\n",
    "\n",
    "    # Convert date string to datetime object\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    # Extract time-based features\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['day_of_year'] = df['date'].dt.dayofyear\n",
    "    \n",
    "    # Drop rows with missing target values\n",
    "    df = df.dropna(subset=['snow_depth_cm'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine 4 location datasets for training the model\n",
    "datasets = [\n",
    "    'data_by_location/Messila_data.csv',\n",
    "    'data_by_location/Purnu_data.csv',\n",
    "    'data_by_location/Ruunarinteet_data.csv',\n",
    "    'data_by_location/Kasurila_data.csv'\n",
    "]\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    try:\n",
    "        df = preprocess_with_time_features(dataset)\n",
    "        all_data.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {dataset}: {e}\")\n",
    "\n",
    "combined_df = pd.concat(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'snow_depth_cm', 'avg_temp_c', 'uv_index', 'cloud_cover_rate',\n",
       "       'cloud_cover', 'location', 'snow_depth_1d_ago', 'snow_depth_7d_ago',\n",
       "       'snow_depth_365d_ago', 'year', 'month', 'day', 'day_of_year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>snow_depth_cm</th>\n",
       "      <th>avg_temp_c</th>\n",
       "      <th>uv_index</th>\n",
       "      <th>cloud_cover_rate</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>location</th>\n",
       "      <th>snow_depth_1d_ago</th>\n",
       "      <th>snow_depth_7d_ago</th>\n",
       "      <th>snow_depth_365d_ago</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>2010-08-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Purnu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>2009-01-27</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>Kasurila</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>2005-10-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Messila</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2005</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4121</th>\n",
       "      <td>2014-06-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Mostly clear</td>\n",
       "      <td>Ruunarinteet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4313</th>\n",
       "      <td>2014-12-30</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Mostly cloudy</td>\n",
       "      <td>Purnu</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5228</th>\n",
       "      <td>2017-07-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Kasurila</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2751</th>\n",
       "      <td>2010-09-20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Mostly cloudy</td>\n",
       "      <td>Kasurila</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5143</th>\n",
       "      <td>2017-04-08</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>Ruunarinteet</td>\n",
       "      <td>17.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>2008-02-07</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>Purnu</td>\n",
       "      <td>34.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5416</th>\n",
       "      <td>2018-01-06</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Mostly cloudy</td>\n",
       "      <td>Kasurila</td>\n",
       "      <td>43.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644</th>\n",
       "      <td>2007-09-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Messila</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2007</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5351</th>\n",
       "      <td>2017-11-02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Kasurila</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3534</th>\n",
       "      <td>2012-11-11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Mostly cloudy</td>\n",
       "      <td>Ruunarinteet</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7337</th>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Mostly clear</td>\n",
       "      <td>Kasurila</td>\n",
       "      <td>37.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5430</th>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>Messila</td>\n",
       "      <td>30.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  snow_depth_cm  avg_temp_c  uv_index  cloud_cover_rate  \\\n",
       "2713 2010-08-13            0.0        20.5       NaN               1.0   \n",
       "2150 2009-01-27           22.0        -4.4       0.0               8.0   \n",
       "942  2005-10-07            0.0         8.3       NaN               0.0   \n",
       "4121 2014-06-21            0.0         8.4       1.0               2.0   \n",
       "4313 2014-12-30           14.0        -4.4       0.0               7.0   \n",
       "5228 2017-07-02            0.0        18.1       1.3               0.0   \n",
       "2751 2010-09-20            0.0         9.8       NaN               7.0   \n",
       "5143 2017-04-08           14.0        -0.1       0.6               8.0   \n",
       "1795 2008-02-07           33.0        -0.1       0.0               8.0   \n",
       "5416 2018-01-06           41.0         0.2       0.0               7.0   \n",
       "1644 2007-09-09            0.0         8.4       0.6               0.0   \n",
       "5351 2017-11-02            3.0        -5.4       0.0               0.0   \n",
       "3534 2012-11-11            3.0         0.8       0.0               7.0   \n",
       "7337 2023-04-11           35.0         3.4       0.5               3.0   \n",
       "5430 2018-01-20           29.0        -3.7       0.0               8.0   \n",
       "\n",
       "        cloud_cover      location  snow_depth_1d_ago  snow_depth_7d_ago  \\\n",
       "2713          Clear         Purnu                0.0                0.0   \n",
       "2150         Cloudy      Kasurila               20.0               10.0   \n",
       "942           Clear       Messila                0.0                0.0   \n",
       "4121   Mostly clear  Ruunarinteet                0.0                0.0   \n",
       "4313  Mostly cloudy         Purnu               12.0               12.0   \n",
       "5228          Clear      Kasurila                0.0                0.0   \n",
       "2751  Mostly cloudy      Kasurila                0.0                0.0   \n",
       "5143         Cloudy  Ruunarinteet               17.0               26.0   \n",
       "1795         Cloudy         Purnu               34.0               24.0   \n",
       "5416  Mostly cloudy      Kasurila               43.0               48.0   \n",
       "1644          Clear       Messila                0.0                0.0   \n",
       "5351          Clear      Kasurila                3.0                0.0   \n",
       "3534  Mostly cloudy  Ruunarinteet                5.0                0.0   \n",
       "7337   Mostly clear      Kasurila               37.0               45.0   \n",
       "5430         Cloudy       Messila               30.0               23.0   \n",
       "\n",
       "      snow_depth_365d_ago  year  month  day  day_of_year  \n",
       "2713                  0.0  2010      8   13          225  \n",
       "2150                 17.0  2009      1   27           27  \n",
       "942                   0.0  2005     10    7          280  \n",
       "4121                  0.0  2014      6   21          172  \n",
       "4313                  0.0  2014     12   30          364  \n",
       "5228                  0.0  2017      7    2          183  \n",
       "2751                  0.0  2010      9   20          263  \n",
       "5143                  7.0  2017      4    8           98  \n",
       "1795                 43.0  2008      2    7           38  \n",
       "5416                 21.0  2018      1    6            6  \n",
       "1644                  0.0  2007      9    9          252  \n",
       "5351                  0.0  2017     11    2          306  \n",
       "3534                  0.0  2012     11   11          316  \n",
       "7337                 53.0  2023      4   11          101  \n",
       "5430                  9.0  2018      1   20           20  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                   datetime64[ns]\n",
       "snow_depth_cm                 float64\n",
       "avg_temp_c                    float64\n",
       "uv_index                      float64\n",
       "cloud_cover_rate              float64\n",
       "cloud_cover                    object\n",
       "location                       object\n",
       "snow_depth_1d_ago             float64\n",
       "snow_depth_7d_ago             float64\n",
       "snow_depth_365d_ago           float64\n",
       "year                            int32\n",
       "month                           int32\n",
       "day                             int32\n",
       "day_of_year                     int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates (if same location and date)\n",
    "combined_df = combined_df.drop_duplicates(subset=['date', 'location'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30076, 14)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location\n",
       "Ruunarinteet    8021\n",
       "Messila         7843\n",
       "Purnu           7163\n",
       "Kasurila        7049\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.location.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['snow_depth_time_model.joblib']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an XGBoost regressor model\n",
    "model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "X = combined_df[['avg_temp_c', \n",
    "                 'cloud_cover_rate',\n",
    "                 'uv_index', \n",
    "                 'snow_depth_1d_ago', \n",
    "                 'snow_depth_7d_ago', \n",
    "                 'snow_depth_365d_ago', \n",
    "                 'year', \n",
    "                 'month', \n",
    "                 'day', \n",
    "                 'day_of_year']]  # Features \n",
    "\n",
    "y = combined_df['snow_depth_cm']  # Target variable (snow depth)\n",
    "\n",
    "# Split into training (80%) and test (20%) data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(model, 'snow_depth_time_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate predictions for testing the model\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.7393424588231221\n",
      "Mean Squared Error: 3.407291535851011\n"
     ]
    }
   ],
   "source": [
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict future years\n",
    "def predict_future_snow_depth(model, start_date, days=365, location_data=None):\n",
    "    \"\"\"\n",
    "    Predict snow depth for future dates\n",
    "    \n",
    "    Parameters:\n",
    "    - model: Trained model\n",
    "    - start_date: Start date for predictions (string YYYY-MM-DD or datetime)\n",
    "    - days: Number of days to predict forward\n",
    "    - location_data: Sample data from a location to use as base values\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with dates and predicted snow depths\n",
    "    \"\"\"\n",
    "    if isinstance(start_date, str):\n",
    "        start_date = pd.to_datetime(start_date)\n",
    "    \n",
    "    # Create date range\n",
    "    future_dates = [start_date + timedelta(days=i) for i in range(days)]\n",
    "    future_df = pd.DataFrame({'date': future_dates})\n",
    "\n",
    "    if location_data is not None:\n",
    "        past_snow_data = location_data[['date', 'snow_depth_cm']].copy()\n",
    "    \n",
    "        past_snow_data['snow_depth_1d_ago'] = past_snow_data['snow_depth_cm'].shift(1)\n",
    "        past_snow_data['snow_depth_7d_ago'] = past_snow_data['snow_depth_cm'].shift(7)\n",
    "        past_snow_data['snow_depth_365d_ago'] = past_snow_data['snow_depth_cm'].shift(365)\n",
    "    \n",
    "        future_df = future_df.merge(past_snow_data[['date', 'snow_depth_1d_ago', 'snow_depth_7d_ago', 'snow_depth_365d_ago']], \n",
    "                                on='date', how='left')\n",
    "    \n",
    "    # Extract time features\n",
    "    future_df['year'] = future_df['date'].dt.year\n",
    "    future_df['month'] = future_df['date'].dt.month\n",
    "    future_df['day'] = future_df['date'].dt.day\n",
    "    future_df['day_of_year'] = future_df['date'].dt.dayofyear\n",
    "    \n",
    "    # Generate weather features based on historical averages by day of year\n",
    "    if location_data is not None:\n",
    "        # Group location data by day of year and get averages\n",
    "        daily_averages = location_data.groupby('day_of_year').agg({\n",
    "            'avg_temp_c': 'mean',\n",
    "            'uv_index': 'mean',\n",
    "            'cloud_cover_rate': 'mean'\n",
    "        }).reset_index()\n",
    "        \n",
    "        # Merge with future dates\n",
    "        future_df = future_df.merge(daily_averages, on='day_of_year', how='left')\n",
    "        \n",
    "        # For days not in historical data, use nearest day\n",
    "        future_df = future_df.fillna(method='ffill').fillna(method='bfill')\n",
    "    else:\n",
    "        # If no location data is provided, use seasonal patterns\n",
    "        # This is simplified - would be better with actual historical weather data\n",
    "        future_df['month_rad'] = future_df['month'] * 2 * np.pi / 12\n",
    "        \n",
    "        # Temperature follows seasonal cycle (simplified model)\n",
    "        # Northern hemisphere: coldest in Jan/Feb, warmest in Jul/Aug\n",
    "        future_df['avg_temp_c'] = -10 * np.cos(future_df['month_rad']) + 5\n",
    "        \n",
    "        # UV follows similar seasonal pattern\n",
    "        future_df['uv_index'] = 3 * np.cos((future_df['month_rad'] + np.pi)) + 3\n",
    "        \n",
    "        # Cloud cover (simplified)\n",
    "        future_df['cloud_cover_rate'] = 0.5 + 0.2 * np.sin(future_df['month_rad'])\n",
    "    \n",
    "    # Prepare features for prediction in the same format as training data\n",
    "    X_future = future_df[['avg_temp_c', \n",
    "                          'cloud_cover_rate',\n",
    "                          'uv_index', \n",
    "                          'snow_depth_1d_ago', \n",
    "                          'snow_depth_7d_ago', \n",
    "                          'snow_depth_365d_ago', \n",
    "                          'year', \n",
    "                          'month', \n",
    "                          'day', \n",
    "                          'day_of_year']]\n",
    "    \n",
    "    # Make predictions\n",
    "    future_df['predicted_snow_depth'] = model.predict(X_future)\n",
    "    \n",
    "    # Ensure non-negative snow depths\n",
    "    future_df['predicted_snow_depth'] = future_df['predicted_snow_depth'].clip(lower=0)\n",
    "    \n",
    "    return future_df[['date', \n",
    "                      'predicted_snow_depth', \n",
    "                      'avg_temp_c', \n",
    "                      'uv_index', \n",
    "                      'cloud_cover_rate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NiinaAhola\\AppData\\Local\\Temp\\ipykernel_18936\\4124380299.py:51: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  future_df = future_df.fillna(method='ffill').fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "# Create prediction files for locations\n",
    "# 1. Load a sample location dataset for reference weather patterns\n",
    "sample_location_salla = preprocess_with_time_features('data_by_location/Salla_data.csv')\n",
    "\n",
    "# 2. Load the trained model\n",
    "trained_model = joblib.load('snow_depth_time_model.joblib')\n",
    "\n",
    "# 3. Predict snow depth for next year starting from a specific date\n",
    "start_prediction_date = '2005-01-01'\n",
    "future_predictions_salla = predict_future_snow_depth(\n",
    "    model=trained_model,\n",
    "    start_date=start_prediction_date,\n",
    "    days=365*40,\n",
    "    location_data=sample_location_salla\n",
    ")\n",
    "future_predictions_salla['location'] = 'Salla'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future predictions saved csv-file\n"
     ]
    }
   ],
   "source": [
    "future_predictions_salla.to_csv('snow_depth_predictions_Salla_2025.csv', index=False)\n",
    "print(\"Future predictions saved csv-file\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
